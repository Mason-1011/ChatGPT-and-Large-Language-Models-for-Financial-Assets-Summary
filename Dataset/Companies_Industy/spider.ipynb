{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-10T12:42:09.727194Z",
     "start_time": "2024-07-10T11:40:35.006896Z"
    }
   },
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_url(url):\n",
    "    session = requests.Session()\n",
    "    retries = Retry(total=5, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "    response = session.get(url, timeout=10)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        company_links = [span.find('a') for span in soup.find_all('span', {'class': 'companyName'})]\n",
    "        company_urls = ['https://www.annualreports.com' + link['href'] for link in company_links if link]\n",
    "        return company_urls\n",
    "    else:\n",
    "        print(f'无法访问网页，状态码: {response.status_code}')\n",
    "        return []\n",
    "\n",
    "def get_info(url):\n",
    "    session = requests.Session()\n",
    "    retries = Retry(total=5, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "    response = session.get(url, timeout=10)\n",
    "    dict = {}\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        dict['Name'] = soup.find('div',class_='vendor_name').get_text(strip=True)\n",
    "        dict['Ticker'] = soup.find('span', class_='ticker_name').text.strip()\n",
    "        dict['Market'] = soup.find('div', class_='right').get_text(strip=True).replace('Exchange','').replace('More','')\n",
    "        dict['Industry'] = soup.find_all('span', class_='blue_txt')[2].find_next_sibling(string=True).strip()\n",
    "        dict['Sector'] = soup.find_all('span', class_='blue_txt')[3].find_next_sibling(string=True).strip()\n",
    "        return dict\n",
    "\n",
    "NYS_list = get_url('https://www.annualreports.com/Companies?exch=1')\n",
    "LSE_list = get_url('https://www.annualreports.com/Companies?exch=9')\n",
    "NAS_list = get_url('https://www.annualreports.com/Companies?exch=2')\n",
    "ASX_list = get_url('https://www.annualreports.com/Companies?exch=7')\n",
    "TSE_list = get_url('https://www.annualreports.com/Companies?exch=5')\n",
    "\n",
    "all_urls = NYS_list + LSE_list + NAS_list + ASX_list + TSE_list\n",
    "\n",
    "list = []\n",
    "for url in tqdm(all_urls, desc='Processing companies'):\n",
    "    info = get_info(url)\n",
    "    if info:\n",
    "        list.append(info)\n",
    "\n",
    "df = pd.DataFrame(list)\n",
    "df.to_csv('Companies_Industry.csv', index=False)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing companies: 100%|██████████| 8787/8787 [1:01:26<00:00,  2.38it/s]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "baa470cc2b77c18f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
